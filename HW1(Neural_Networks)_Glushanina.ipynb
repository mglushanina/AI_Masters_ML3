{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQwlunyE86kE"
      },
      "source": [
        "# 1. Практическое задание. Обучение полносвязной нейронной сети.\n",
        "\n",
        "**ФИО**: Глушанина Мария Евгеньевна\n",
        "\n",
        "**Дедлайн**: 13 октября 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyCGfNgA86kF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "\n",
        "from glob import glob\n",
        "from collections import OrderedDict\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torch.autograd import Function\n",
        "from torch.autograd import gradcheck\n",
        "from torch.optim import Optimizer, Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFaWrLT4GkfY"
      },
      "source": [
        "## 1. Загрузка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R930jTYMG6nB"
      },
      "source": [
        "Если вам требуется работать с каким-нибубь набором данных (dataset), то прежде всего проверьте нет ли его среди встроенных наборов данных https://pytorch.org/vision/stable/datasets.html.\n",
        "\n",
        "В текущем домашнем задании мы будем работать с набором данных FashionMNIST. Он присутствует в списке встроенных наборов данных, однако мы воспользуемся реализацией только для удобного и быстрого способа скачать наборы данных. Ниже предлагается реализовать собственный класс для считывания, обработки и упаковки данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LauGpMvGF5qr",
        "outputId": "deb5b4b0-4b71-4921-c5e8-343746cdb19f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 13181513.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 207331.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3929201.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 15152475.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIT32OCMaLLP"
      },
      "source": [
        "Воспользуемся функцией загрузки данных из репозитория наборов данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm_cf_hEIapm",
        "outputId": "a6aeba3c-ef0e-4e8d-fb38-843b04695c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t10k-images-idx3-ubyte\t   train-images-idx3-ubyte\n",
            "t10k-images-idx3-ubyte.gz  train-images-idx3-ubyte.gz\n",
            "t10k-labels-idx1-ubyte\t   train-labels-idx1-ubyte\n",
            "t10k-labels-idx1-ubyte.gz  train-labels-idx1-ubyte.gz\n"
          ]
        }
      ],
      "source": [
        "! ls data/FashionMNIST/raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xnY5xk1KBg2"
      },
      "outputs": [],
      "source": [
        "#https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
        "\n",
        "def load_mnist(path, kind='train'):\n",
        "    import os\n",
        "    import gzip\n",
        "    import numpy as np\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHIlWRV0aZnA"
      },
      "source": [
        "Для удобства PyTorch предоставляет ряд базовых классов `Dataset, DataLoader`, от которых предлагается отнаследоваться при разработке пользовательских классов. Базовый класс `Dataset` используется для загрузки и обработки данных, класс `DataLoader` используется для управления процессом загрузки данных, позволяет в многопоточном режиме загружать данные и упаковывать их.\n",
        "Эти вспомогательные классы находятся в модуле `torch.utils.data`.\n",
        "\n",
        "При наследовании от класса `torch.utils.data.Dataset` требуется переопределить метод `__len__`, который возвращает количество примеров в наборе данных, а также метод `__getitem__`, который позволяет получить доступ к примеру из набора данных по индексу."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jf2e5cPbJV2"
      },
      "source": [
        "Реализуем класс для FasionMnist.\n",
        "\n",
        "Элементами датасета должны являться пары '(np.array, int)', массив имеет размерность `(28, 28)`, тип элемента `np.float32`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snTBHRTQI1bc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "class FashionMnist(Dataset):\n",
        "    def __init__(self, path, train=True, image_transform=None,\n",
        "                 label_transform=None):\n",
        "        if train:\n",
        "            images, labels = load_mnist(os.path.join(path,\"raw\"))\n",
        "        else:\n",
        "            images, labels = load_mnist(os.path.join(path,\"raw\"), kind=\"t10k\")\n",
        "\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.image_transform = image_transform\n",
        "        self.label_transform = label_transform\n",
        "\n",
        "    def __len__(self,):\n",
        "        length = len(self.images)\n",
        "        return length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_item = self.images[idx].reshape(28,28).astype(np.float32)\n",
        "        label_item = int(self.labels[idx])\n",
        "\n",
        "        if self.image_transform is not None:\n",
        "            data_item = self.image_transform(data_item)\n",
        "        if self.label_transform is not None:\n",
        "            label_item = self.label_transform(label_item)\n",
        "\n",
        "        return data_item, label_item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVGv_2zBNfpz"
      },
      "outputs": [],
      "source": [
        "test_dataset = FashionMnist(\"data/FashionMNIST\", train=False)\n",
        "train_dataset = FashionMnist(\"data/FashionMNIST\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt92k7sWn372",
        "outputId": "21113d7b-cb8f-422d-a39e-d8cb551574fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.float32"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_dataset[0][0][0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JciETIfndiGR"
      },
      "source": [
        "Визуализируйте случайные элементы набора данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "wBky4UtmOS71",
        "outputId": "683b7fc4-b15a-4078-a6be-95be1562eb00"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeFElEQVR4nO3dfXCU9d3v8c/maXlKNoaQpxIwoIAViVMKKUelWHLz0Ps4oPzhU88Bx8EjDU6RWh16q2jvzkmLc6yjQ/H80UKdEbXOCIxOS28NJty2gQ4IQ2k1JTSWUJIg3M1uCGYJye/8wXHblQT4Lbt8k/B+zVwz7HVd372++8uVfLiyV34bcM45AQBwhaVZNwAAuDoRQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADCRYd3AF/X29urYsWPKzs5WIBCwbgcA4Mk5p46ODpWUlCgtrf/rnAEXQMeOHVNpaal1GwCAy9Tc3KyxY8f2u33ABVB2drYk6VZ9UxnKNO4GAODrrLr1gX4V+3nen5QF0Pr16/Xcc8+ptbVV5eXleumllzRz5syL1n3+a7cMZSojQAABwKDz/2cYvdjbKCm5CeGNN97Q6tWrtXbtWn344YcqLy/X/Pnzdfz48VQcDgAwCKUkgJ5//nktX75cDzzwgL785S/r5Zdf1ogRI/Tzn/88FYcDAAxCSQ+gM2fOaO/evaqsrPzHQdLSVFlZqfr6+vP2j0ajikQicQsAYOhLegCdOHFCPT09KiwsjFtfWFio1tbW8/avrq5WKBSKLdwBBwBXB/M/RF2zZo3C4XBsaW5utm4JAHAFJP0uuPz8fKWnp6utrS1ufVtbm4qKis7bPxgMKhgMJrsNAMAAl/QroKysLE2fPl01NTWxdb29vaqpqdGsWbOSfTgAwCCVkr8DWr16tZYuXaqvfvWrmjlzpl544QV1dnbqgQceSMXhAACDUEoC6O6779ann36qp59+Wq2trbr55pu1ffv2825MAABcvQLOOWfdxD+LRCIKhUKao0XMhAAAg9BZ161abVM4HFZOTk6/+5nfBQcAuDoRQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARNID6JlnnlEgEIhbpkyZkuzDAAAGuYxUPOmNN96o99577x8HyUjJYQAAg1hKkiEjI0NFRUWpeGoAwBCRkveADh06pJKSEk2YMEH333+/jhw50u++0WhUkUgkbgEADH1JD6CKigpt2rRJ27dv14YNG9TU1KTbbrtNHR0dfe5fXV2tUCgUW0pLS5PdEgBgAAo451wqD9De3q7x48fr+eef14MPPnje9mg0qmg0GnsciURUWlqqOVqkjEBmKlsDAKTAWdetWm1TOBxWTk5Ov/ul/O6A3NxcTZo0SY2NjX1uDwaDCgaDqW4DADDApPzvgE6dOqXDhw+ruLg41YcCAAwiSQ+gxx57THV1dfrkk0/0u9/9TnfeeafS09N17733JvtQAIBBLOm/gjt69KjuvfdenTx5UmPGjNGtt96qXbt2acyYMck+FABgEEt6AL3++uvJfkoAwBDEXHAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARIZ1A8BgF8jw/zZyPT3+B3LOuyQ9f7T/cSQ1fXuyd824H/wuoWN5CwT8axIYuysqkdeUqAE0FlwBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMMFkpMBlcmfPXpHjZJSO9a5Z9B8fJnSs//PWpITqrogBNJlm0gzF13QJuAICAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggslIAQNHnvlv3jVlX//Eu2b/qXHeNZLk0hMqA7xwBQQAMEEAAQBMeAfQzp07dccdd6ikpESBQEBbt26N2+6c09NPP63i4mINHz5clZWVOnToULL6BQAMEd4B1NnZqfLycq1fv77P7evWrdOLL76ol19+Wbt379bIkSM1f/58dXV1XXazAIChw/smhIULF2rhwoV9bnPO6YUXXtCTTz6pRYsWSZJeeeUVFRYWauvWrbrnnnsur1sAwJCR1PeAmpqa1NraqsrKyti6UCikiooK1dfX91kTjUYViUTiFgDA0JfUAGptbZUkFRYWxq0vLCyMbfui6upqhUKh2FJaWprMlgAAA5T5XXBr1qxROByOLc3NzdYtAQCugKQGUFFRkSSpra0tbn1bW1ts2xcFg0Hl5OTELQCAoS+pAVRWVqaioiLV1NTE1kUiEe3evVuzZs1K5qEAAIOc911wp06dUmNjY+xxU1OT9u/fr7y8PI0bN06rVq3SD3/4Q11//fUqKyvTU089pZKSEi1evDiZfQMABjnvANqzZ49uv/322OPVq1dLkpYuXapNmzbp8ccfV2dnpx566CG1t7fr1ltv1fbt2zVs2LDkdQ0AGPQCzjln3cQ/i0QiCoVCmqNFyghkWreDq8wnP/T/VfH/Wvwb75q2bv/3OuuPl3nXHG29xrtGkv7lho+8a2r/42bvmmuf7PvPM642f355pndNZm5if9xfds+BhOp8nHXdqtU2hcPhC76vb34XHADg6kQAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMOH9cQxDSSBjYL9819OTQNGAmtzczF9+nNgHIB76Hxu8a27/4yLvmk/+UuBdo6xe75KMYALnkKT3GqZ419wy94/eNV1zRnvXNLw52btm9B+j3jWSlNXuX/fXf/Wf6XzEmLB3TTSa2KcFJPJzz509m9CxLoYrIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYG9mycKZaqCfauGmnp3iV/+dFM75pvza/zrpl4Zp93jSRN2vk/vWu624cldCxfgTT/iWZ7zib2f8xAwP9Y//kH/0lCle5/nHn3+39tczK6vGskKS2BcWj56w3eNadO+Z9DwWHd3jWS9OmDM7xr8v9vfULHuhiugAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJi4qicjzbh2XEJ1vZ+e9C/q6fEuScsNedecnFvmXfNf//0z7xpJevim//Su2d/xR++aP0RKvGs+bErsa5uR6f91Gp5/2rtmQr7/OfSXE6O9a/KzO71rJKmjK+hd89VJzd417x30n7hz36djvWui3Yn9qOuIDPeuScvo9a4ZNcp/stSzPYldP0SvCSRUlwpcAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADAxcCcjnXGjlDHsknf/+1P+E2pOyWvzrpGkltN53jXRs/5DPSor6l0zLvOQd00o6j/hoiT98shXvGtOJTDJ5bhr/u5dM7bQv0aS/vZprneNc/6TO544PdK7pqszy7vm6Gn/GkmS8y+p7bzeuyZj+FnvmhMnsr1rAukJvKAEuV7/8yHyX/7nw5jCsHeNJJ36aiShulTgCggAYIIAAgCY8A6gnTt36o477lBJSYkCgYC2bt0at33ZsmUKBAJxy4IFC5LVLwBgiPAOoM7OTpWXl2v9+vX97rNgwQK1tLTEltdee+2ymgQADD3e74wvXLhQCxcuvOA+wWBQRUVFCTcFABj6UvIeUG1trQoKCjR58mStWLFCJ0/2//HD0WhUkUgkbgEADH1JD6AFCxbolVdeUU1NjX784x+rrq5OCxcuVE9PT5/7V1dXKxQKxZbS0tJktwQAGICS/ndA99xzT+zfN910k6ZNm6aJEyeqtrZWc+fOPW//NWvWaPXq1bHHkUiEEAKAq0DKb8OeMGGC8vPz1djY2Of2YDConJycuAUAMPSlPICOHj2qkydPqri4ONWHAgAMIt6/gjt16lTc1UxTU5P279+vvLw85eXl6dlnn9WSJUtUVFSkw4cP6/HHH9d1112n+fPnJ7VxAMDg5h1Ae/bs0e233x57/Pn7N0uXLtWGDRt04MAB/eIXv1B7e7tKSko0b948/fu//7uCQf85wAAAQ5d3AM2ZM0fO9T+x329+85vLauhzHeNHKCPz0icjvTb0N+9jdPVketdIUmZa33f0XUhahv9kiJHopb/+z/0tHPKuSQskNlFjIIG69LRe75pDLQXeNbk5p71rJCkn239S22Cm/4SaGQmMw62T+n4f9UIKgx3eNZI0Kt1/ItzMgP/3RdT53weVlsBMqd0u3bsmUaEM/3PvreabvWtO/MH/+0KSvlTrf76mCnPBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMJP0juZNlxPEzysi49Hw8/r8neB+jszCxl9/+L/4zJpeXHvWumV/4J++aksy/e9dEeod710jSie5s75phad3eNYnMstzR4z+TuCRlpvnPFHwqgWOFz/qP+Y7m671rToUT+9oq4j9TfPCE/4zTaWe8S5TR5V+T/lliM74ncLpqZJv/+Zr3p+PeNTmf/N67RpLSr7vWv6jQb+Zt13tGuoSXxBUQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwN2MtLMPX9WRiDrkvdv/rdy72MMOxHwrpGk67/d5F3z2TD/CStrMr/sXdN7zSjvmpNfuca7RpI6i/3HLz3qf5xgu/9EklmnEpt8cuTf/Ge6zGg85l3jwhHvmpKew941iXI9/hNqyvUmv5E+pA33n2A1rXBMQsdyHae8awKjRnrXdBf7fw9mBP0njJWknlAC4zf80n8WS5LriTIZKQBg4CKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGBiwE5G2nv6M/UGzl7y/tf+W733MTru/pp3jSR9tG6Sd80Tt/7Ku2bDn2d714x8LeRdk7/7hHeNJF3z0SHvmrTsbO+anqkTvGsCuw5410hSxrXjvGuiN4z1rukJ+v/fr2u0/7drb3piE+4qgbL0MwlMAJtASU+Wf3O9ic3bqUAC86tmdiZQFEjgNZX5TyoqSV15/udewR6/SVl7z17aZLZcAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADAxYCcjvRKy39iVYJ1/zRaN8a4pnu7//4OW2/xrWv/Vf4JQSRqVc4N3zdhQ2Ltm0qiPvWt+/fHN3jWS5Hr9J4VMO5HlXdOblcAsnGn+NWld/oeRpJ7sS5tMMk4CY5fIa0rkOBnt6f7HkZSWwDCkRf2PNSyB+YDzPo76F0m6Zq//92BPQ6Nfgeu+pN24AgIAmCCAAAAmvAKourpaM2bMUHZ2tgoKCrR48WI1NDTE7dPV1aWqqiqNHj1ao0aN0pIlS9TW1pbUpgEAg59XANXV1amqqkq7du3Su+++q+7ubs2bN0+dnZ2xfR599FG9/fbbevPNN1VXV6djx47prrvuSnrjAIDBzesmhO3bt8c93rRpkwoKCrR3717Nnj1b4XBYP/vZz7R582Z94xvfkCRt3LhRN9xwg3bt2qWvfS2xTyAFAAw9l/UeUDh87m6KvLw8SdLevXvV3d2tysrK2D5TpkzRuHHjVF/f90dmR6NRRSKRuAUAMPQlHEC9vb1atWqVbrnlFk2dOlWS1NraqqysLOXm5sbtW1hYqNbW1j6fp7q6WqFQKLaUlpYm2hIAYBBJOICqqqp08OBBvf7665fVwJo1axQOh2NLc3PzZT0fAGBwSOgPUVeuXKl33nlHO3fu1NixY2Pri4qKdObMGbW3t8ddBbW1tamoqKjP5woGgwoGg4m0AQAYxLyugJxzWrlypbZs2aIdO3aorKwsbvv06dOVmZmpmpqa2LqGhgYdOXJEs2bNSk7HAIAhwesKqKqqSps3b9a2bduUnZ0de18nFApp+PDhCoVCevDBB7V69Wrl5eUpJydHjzzyiGbNmsUdcACAOF4BtGHDBknSnDlz4tZv3LhRy5YtkyT95Cc/UVpampYsWaJoNKr58+frpz/9aVKaBQAMHQHnXAKzAaZOJBJRKBTSHC1SRiDTuh0AgKezrlu12qZwOKycnJx+92MuOACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJjwCqDq6mrNmDFD2dnZKigo0OLFi9XQ0BC3z5w5cxQIBOKWhx9+OKlNAwAGP68AqqurU1VVlXbt2qV3331X3d3dmjdvnjo7O+P2W758uVpaWmLLunXrkto0AGDwy/DZefv27XGPN23apIKCAu3du1ezZ8+OrR8xYoSKioqS0yEAYEi6rPeAwuGwJCkvLy9u/auvvqr8/HxNnTpVa9as0enTp/t9jmg0qkgkErcAAIY+ryugf9bb26tVq1bplltu0dSpU2Pr77vvPo0fP14lJSU6cOCAnnjiCTU0NOitt97q83mqq6v17LPPJtoGAGCQCjjnXCKFK1as0K9//Wt98MEHGjt2bL/77dixQ3PnzlVjY6MmTpx43vZoNKpoNBp7HIlEVFpaqjlapIxAZiKtAQAMnXXdqtU2hcNh5eTk9LtfQldAK1eu1DvvvKOdO3deMHwkqaKiQpL6DaBgMKhgMJhIGwCAQcwrgJxzeuSRR7RlyxbV1taqrKzsojX79++XJBUXFyfUIABgaPIKoKqqKm3evFnbtm1Tdna2WltbJUmhUEjDhw/X4cOHtXnzZn3zm9/U6NGjdeDAAT366KOaPXu2pk2blpIXAAAYnLzeAwoEAn2u37hxo5YtW6bm5mZ961vf0sGDB9XZ2anS0lLdeeedevLJJy/4e8B/FolEFAqFeA8IAAaplLwHdLGsKi0tVV1dnc9TAgCuUswFBwAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwkWHdwBc55yRJZ9UtOeNmAADezqpb0j9+nvdnwAVQR0eHJOkD/cq4EwDA5ejo6FAoFOp3e8BdLKKusN7eXh07dkzZ2dkKBAJx2yKRiEpLS9Xc3KycnByjDu0xDucwDucwDucwDucMhHFwzqmjo0MlJSVKS+v/nZ4BdwWUlpamsWPHXnCfnJycq/oE+xzjcA7jcA7jcA7jcI71OFzoyudz3IQAADBBAAEATAyqAAoGg1q7dq2CwaB1K6YYh3MYh3MYh3MYh3MG0zgMuJsQAABXh0F1BQQAGDoIIACACQIIAGCCAAIAmBg0AbR+/Xpde+21GjZsmCoqKvT73//euqUr7plnnlEgEIhbpkyZYt1Wyu3cuVN33HGHSkpKFAgEtHXr1rjtzjk9/fTTKi4u1vDhw1VZWalDhw7ZNJtCFxuHZcuWnXd+LFiwwKbZFKmurtaMGTOUnZ2tgoICLV68WA0NDXH7dHV1qaqqSqNHj9aoUaO0ZMkStbW1GXWcGpcyDnPmzDnvfHj44YeNOu7boAigN954Q6tXr9batWv14Ycfqry8XPPnz9fx48etW7vibrzxRrW0tMSWDz74wLqllOvs7FR5ebnWr1/f5/Z169bpxRdf1Msvv6zdu3dr5MiRmj9/vrq6uq5wp6l1sXGQpAULFsSdH6+99toV7DD16urqVFVVpV27dundd99Vd3e35s2bp87Oztg+jz76qN5++229+eabqqur07Fjx3TXXXcZdp18lzIOkrR8+fK482HdunVGHffDDQIzZ850VVVVscc9PT2upKTEVVdXG3Z15a1du9aVl5dbt2FKktuyZUvscW9vrysqKnLPPfdcbF17e7sLBoPutddeM+jwyvjiODjn3NKlS92iRYtM+rFy/PhxJ8nV1dU558597TMzM92bb74Z2+ejjz5yklx9fb1Vmyn3xXFwzrmvf/3r7jvf+Y5dU5dgwF8BnTlzRnv37lVlZWVsXVpamiorK1VfX2/YmY1Dhw6ppKREEyZM0P33368jR45Yt2SqqalJra2tcedHKBRSRUXFVXl+1NbWqqCgQJMnT9aKFSt08uRJ65ZSKhwOS5Ly8vIkSXv37lV3d3fc+TBlyhSNGzduSJ8PXxyHz7366qvKz8/X1KlTtWbNGp0+fdqivX4NuMlIv+jEiRPq6elRYWFh3PrCwkJ9/PHHRl3ZqKio0KZNmzR58mS1tLTo2Wef1W233aaDBw8qOzvbuj0Tra2tktTn+fH5tqvFggULdNddd6msrEyHDx/W97//fS1cuFD19fVKT0+3bi/pent7tWrVKt1yyy2aOnWqpHPnQ1ZWlnJzc+P2HcrnQ1/jIEn33Xefxo8fr5KSEh04cEBPPPGEGhoa9NZbbxl2G2/ABxD+YeHChbF/T5s2TRUVFRo/frx++ctf6sEHHzTsDAPBPffcE/v3TTfdpGnTpmnixImqra3V3LlzDTtLjaqqKh08ePCqeB/0Qvobh4ceeij275tuuknFxcWaO3euDh8+rIkTJ17pNvs04H8Fl5+fr/T09PPuYmlra1NRUZFRVwNDbm6uJk2apMbGRutWzHx+DnB+nG/ChAnKz88fkufHypUr9c477+j999+P+/iWoqIinTlzRu3t7XH7D9Xzob9x6EtFRYUkDajzYcAHUFZWlqZPn66amprYut7eXtXU1GjWrFmGndk7deqUDh8+rOLiYutWzJSVlamoqCju/IhEItq9e/dVf34cPXpUJ0+eHFLnh3NOK1eu1JYtW7Rjxw6VlZXFbZ8+fboyMzPjzoeGhgYdOXJkSJ0PFxuHvuzfv1+SBtb5YH0XxKV4/fXXXTAYdJs2bXJ/+tOf3EMPPeRyc3Nda2urdWtX1He/+11XW1vrmpqa3G9/+1tXWVnp8vPz3fHjx61bS6mOjg63b98+t2/fPifJPf/8827fvn3ur3/9q3POuR/96EcuNzfXbdu2zR04cMAtWrTIlZWVuc8++8y48+S60Dh0dHS4xx57zNXX17umpib33nvvua985Svu+uuvd11dXdatJ82KFStcKBRytbW1rqWlJbacPn06ts/DDz/sxo0b53bs2OH27NnjZs2a5WbNmmXYdfJdbBwaGxvdD37wA7dnzx7X1NTktm3b5iZMmOBmz55t3Hm8QRFAzjn30ksvuXHjxrmsrCw3c+ZMt2vXLuuWrri7777bFRcXu6ysLPelL33J3X333a6xsdG6rZR7//33naTzlqVLlzrnzt2K/dRTT7nCwkIXDAbd3LlzXUNDg23TKXChcTh9+rSbN2+eGzNmjMvMzHTjx493y5cvH3L/Sevr9UtyGzdujO3z2WefuW9/+9vummuucSNGjHB33nmna2lpsWs6BS42DkeOHHGzZ892eXl5LhgMuuuuu85973vfc+Fw2LbxL+DjGAAAJgb8e0AAgKGJAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAif8H0V9enRktrQEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def plot_random_item(df):\n",
        "    num = random.randint(0, df.__len__())\n",
        "    plt.imshow(df.__getitem__(num)[0])\n",
        "\n",
        "\n",
        "plot_random_item(train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "320RvzL7PZrI"
      },
      "source": [
        "В конструктор `Dataset` можно передать объект `torchvision.transforms`, который позволяет преобразовать исходные данные. Преобразование `torchvision.transforms.ToTensor` позволяет преобразоать данные из типа `PIL Image` и `numpy.float32` в тип `torch.float32`\n",
        "\n",
        "Реализуйте собственную поддержку преобразований в `FashionMnist`. Проверьте, что приведение типов работает корректно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQsGbfXUTxcx"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "from torch import from_numpy\n",
        "\n",
        "class CustomToTensor(ToTensor):\n",
        "    def __call__(self, sample):\n",
        "        return torch.tensor(sample, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BpFQ_Y2PoeI"
      },
      "outputs": [],
      "source": [
        "transform = CustomToTensor()\n",
        "t_right = ToTensor()\n",
        "\n",
        "test_dataset = FashionMnist(\"data/FashionMNIST\",\n",
        "                            train=False,\n",
        "                            image_transform=transform,\n",
        "                            label_transform=None\n",
        "                            )\n",
        "train_dataset = FashionMnist(\"data/FashionMNIST\",\n",
        "                             image_transform=transform,\n",
        "                             label_transform=None\n",
        "                             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukLn9rY7SCsS",
        "outputId": "3a07afd2-c668-4cfe-c979-16265b61a398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The type of the data is torch.float32\n"
          ]
        }
      ],
      "source": [
        "print(f\"The type of the data is {train_dataset[0][0][0][0].dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ltavx0QUMnm"
      },
      "source": [
        "Элементы набора данных могут быть объединены в пакеты (batch) явно и неявно. Если данные могут быть сконкатенированы или обЪединены каким-нибудь тривиальным способом, то можно не передавать никаких дополнительных парамертов в `torch.utils.data.Dataloader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cizxx6m0VAI7"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(test_dataset, batch_size=15, num_workers=2, shuffle=True)\n",
        "batch = next(iter(test_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIZiPrBgVwGA",
        "outputId": "d0ef5f4b-ff31-4aac-a125-17ddc686c82b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the batch is 2\n",
            "The shape of the batch[0] is torch.Size([15, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "print(f\"The length of the batch is {len(batch)}\")\n",
        "print(f\"The shape of the batch[0] is {batch[0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCggRyOQWVIx"
      },
      "source": [
        "Однако, если наша структура данных не позволяет нам использовать объединение по умолчанию, то можно написать собственную функцию, которая будет пакетировать данные.\n",
        "\n",
        "Реализуйте функцию, преобразующую последовательность элементов массива в пакет (batch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQVh93fmWSjA"
      },
      "outputs": [],
      "source": [
        "def collate(batch):\n",
        "    images, labels = zip(*batch)\n",
        "\n",
        "    # Стекируем изображения и метки в соответствующие тензоры\n",
        "    image_batch = torch.stack([img for img in images], dim=0)\n",
        "    label_batch = torch.tensor(labels)\n",
        "\n",
        "    return image_batch, label_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wij6F-vpe7KS"
      },
      "source": [
        "Убедитесть, что все работает корректно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dDtlvlCXNbW"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(test_dataset, batch_size=15, num_workers=2,\n",
        "                             shuffle=True, collate_fn=collate)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=15, num_workers=2,\n",
        "                              shuffle=True, collate_fn=collate)\n",
        "batch = next(iter(test_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFN00IyZXYaF",
        "outputId": "9e5418ba-8002-479b-b876-f74f3f88bc5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the batch is 2\n",
            "The shape of the batch[0] is torch.Size([15, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "print(f\"The length of the batch is {len(batch)}\")\n",
        "print(f\"The shape of the batch[0] is {batch[0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHcumwuF86kL"
      },
      "source": [
        "## 2. Реализация модулей нейронной сети (15 баллов)\n",
        "\n",
        "В этом разделе мы полностью реализуем модули для полносвязанной сети.\n",
        "\n",
        "Для начала нам понадобится реализовать прямой и обратный проход через слои.\n",
        "\n",
        "Наши слои будут соответствовать следующему интерфейсу (на примере \"тождественного\" слоя):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzhCW5HcfmKd"
      },
      "source": [
        "Сначала, мы реализуем функцию и её градиент."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcqeFXxsFGQO"
      },
      "outputs": [],
      "source": [
        "class IdentityFunction(Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "        \"\"\"\n",
        "        return input\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "        \"\"\"\n",
        "        return grad_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc6Rtczffxv4"
      },
      "source": [
        "Разработанную функцию обернем классом `IdentityLayer`, все слои в `PyTorch` должны быть наследниками базового класса `nn.Module()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiqeRVcM86kM"
      },
      "outputs": [],
      "source": [
        "class IdentityLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        # An identity layer does nothing\n",
        "        super().__init__()\n",
        "        self.identity = IdentityFunction.apply\n",
        "\n",
        "    def forward(self, inp):\n",
        "        # An identity layer just returns whatever it gets as input.\n",
        "        return self.identity(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4IoM_pX86kQ"
      },
      "source": [
        "\n",
        "### 2.1 Функция активации ReLU\n",
        "Для начала реализуем функцию активации, слой нелинейности `ReLU(x) = max(x, 0)`. Параметров у слоя нет. Метод `forward` должен вернуть результат поэлементного применения `ReLU` к входному массиву, метод `backward` - градиент функции потерь по входу слоя. В нуле будем считать производную равной 0. Обратите внимание, что при обратном проходе могут понадобиться величины, посчитанные во время прямого прохода, поэтому их стоит сохранить в `ctx`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9qrJ47xY6H0"
      },
      "outputs": [],
      "source": [
        "class ReLUFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        output = np.maximum(0, input)\n",
        "        ctx.save_for_backward(input)\n",
        "\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input<0] = 0\n",
        "\n",
        "        return grad_input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y09ZVCsT86kT"
      },
      "outputs": [],
      "source": [
        "class ReLU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ReLU, self).__init__()\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        return ReLUFunction.apply(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RwKEUp_V3-L"
      },
      "source": [
        "Не забываем после реализации функции проверить градиент, испльзуя функцию `gradcheck`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0RnDQZCXXZn"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(5, requires_grad=True, dtype=torch.float64)\n",
        "relu = ReLU()\n",
        "\n",
        "assert gradcheck(relu, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUmbmR4iXurd"
      },
      "outputs": [],
      "source": [
        "torch_relu = torch.nn.ReLU()\n",
        "our_relu = ReLU()\n",
        "\n",
        "assert torch.norm(torch_relu(x.float()) - our_relu(x)) < 1e-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojTR4GFd86kY"
      },
      "source": [
        "### 2.2 Линейный слой (linear, fully-connected)\n",
        "Далее реализуем полносвязный слой без нелинейности. У слоя два набора параметра: матрица весов (weights) и вектор смещения (bias)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBl34oykbcBf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LinearFunction(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    Custom autograd function for a simple linear function: y = wx + b\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, w, b):\n",
        "        ctx.save_for_backward(x, w, b)\n",
        "        output = torch.mm(x, w.t()) + b\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        x, w, b = ctx.saved_tensors\n",
        "        grad_input = torch.mm(grad_output, w)\n",
        "        grad_weight = torch.mm(grad_output.t(), x)\n",
        "        grad_bias = grad_output.sum(0)\n",
        "\n",
        "        return grad_input, grad_weight, grad_bias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbN5JOc886kZ"
      },
      "outputs": [],
      "source": [
        "class Linear(nn.Module):\n",
        "    \"\"\"\n",
        "    Custom linear layer for a neural network: y = wx + b\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(Linear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "\n",
        "        # Initialize parameters\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        if self.bias is not None:\n",
        "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
        "            bound = 1 / math.sqrt(fan_in)\n",
        "            nn.init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return LinearFunction.apply(x, self.weight, self.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gToXI43WYMDv"
      },
      "source": [
        "Проверим градиент, а также сравним с работой нашего модуля с имплементированным в `PyTorch`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et7mKX5xZfMI"
      },
      "source": [
        "Проверка градиента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxLVozqLZb_H"
      },
      "outputs": [],
      "source": [
        "input_data = torch.randn(5, 3, requires_grad=True, dtype=torch.float64)\n",
        "weight = torch.randn(4, 3, requires_grad=True, dtype=torch.float64)\n",
        "bias = torch.randn(4, requires_grad=True, dtype=torch.float64)\n",
        "assert gradcheck(LinearFunction.apply, (input_data, weight, bias), eps=1e-6, atol=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW8ppOciZndN"
      },
      "source": [
        "Сравнение с `PyTorch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIR9svs7Zmq0",
        "outputId": "d9a36462-f09f-4513-c289-40138538b327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs match between our linear and torch linear.\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "our_linear = Linear(3, 4)\n",
        "torch_linear = nn.Linear(3, 4)\n",
        "\n",
        "weight = torch.randn(4, 3)\n",
        "bias = torch.randn(4)\n",
        "\n",
        "state_dict = OrderedDict([(\"weight\", weight), (\"bias\", bias)])\n",
        "torch_linear.load_state_dict(state_dict)\n",
        "our_linear.load_state_dict(state_dict)\n",
        "\n",
        "input_data = torch.randn(5, 3)\n",
        "output_our = our_linear(input_data)\n",
        "output_torch = torch_linear(input_data)\n",
        "\n",
        "if torch.allclose(output_our, output_torch):\n",
        "    print(\"Outputs match between our linear and torch linear.\")\n",
        "else:\n",
        "    print(\"Outputs do not match between our linear and torch linear.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dyhDg0D86kt"
      },
      "source": [
        "### 2.3 LogSoftmax (Log + Softmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArL0HLGH86ku"
      },
      "source": [
        "Для решения задачи многоклассовой классификации обычно используют `softmax` в качестве нелинейности на последнем слое, чтобы получить \"оценку\" вероятности классов для каждого объекта:$$\\hat y = softmax(x)  = \\bigl \\{\\frac {exp(x_i)}{\\sum_j exp(x_j)} \\bigr \\}_{i=1}^K, \\quad K - \\text{число классов}$$В этом случае удобно оптимизировать логарифм правдоподобия:$$L(y, \\hat y) = -\\sum_{i=1}^K y_i \\log \\hat y_i \\rightarrow \\min,$$где $y_i=1$, если объект принадлежит $i$-му классу, и 0 иначе. Записанная в таком виде, эта функция потерь совпадает с выражением для кросс-энтропии. Очевидно, что ее также можно переписать через индексацию, если через $y_i$ обозначить класс данного объекта:$$L(y, \\hat y) = - \\log \\hat y_{y_i} \\rightarrow \\min$$В таком виде ее удобно реализовывать.\n",
        "\n",
        "Реализуйте слой `LogSoftmax` (без параметров). Метод `forward` должен вычислять логарифм от `softmax`, а метод `backward` - пропускать градиенты. В общем случае в промежуточных вычислениях `backward` получится трехмерный тензор, однако для нашей конкретной функции потерь все вычисления можно реализовать в матричном виде. Поэтому мы будем предполагать, что аргумент `grad_output` - это матрица, у которой в каждой строке только одно ненулевое значение (не обязательно единица).\n",
        "\n",
        "Комментарий: разобраться `Log-Sum-Exp trick`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSV3XD0N86ky"
      },
      "outputs": [],
      "source": [
        "class LogSoftmaxFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, inp):\n",
        "        max_val, _ = inp.max(dim=1, keepdim=True)\n",
        "        log_softmax = inp - max_val - torch.log(torch.exp(inp - max_val).sum(dim=1, keepdim=True))\n",
        "\n",
        "        ctx.save_for_backward(log_softmax)\n",
        "        return log_softmax\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        log_softmax, = ctx.saved_tensors\n",
        "        softmax = torch.exp(log_softmax)\n",
        "        grad_input = grad_output - softmax * grad_output.sum(dim=1, keepdim=True)\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7OnC6o_z2vg"
      },
      "outputs": [],
      "source": [
        "class LogSoftmax(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LogSoftmax, self).__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return LogSoftmaxFunction.apply(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke4G67cddjVA"
      },
      "source": [
        "Проверка градиентов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfgkVgGbrQEv"
      },
      "outputs": [],
      "source": [
        "input_data = torch.randn(5, 3, requires_grad=True, dtype=torch.float64)\n",
        "logsoftmax_layer = LogSoftmax()\n",
        "assert gradcheck(logsoftmax_layer, (input_data,)), \"Gradient check for LogSoftmax Module failed\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sn2M_Q086k2"
      },
      "source": [
        "### 2.4 Dropout\n",
        "Реализуйте слой Dropout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCLECy1y86k3"
      },
      "outputs": [],
      "source": [
        "class DropoutFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, inp, p):\n",
        "        mask = torch.rand_like(inp) > p\n",
        "        ctx.save_for_backward(mask)\n",
        "        return inp * mask / (1-p)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        mask, = ctx.saved_tensors\n",
        "        return grad_output * mask, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS5z_mth1ZAZ"
      },
      "outputs": [],
      "source": [
        "class Dropout(nn.Module):\n",
        "    def __init__(self, p):\n",
        "        super(Dropout, self).__init__()\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, input):\n",
        "        return DropoutFunction.apply(input, self.p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyPPzkCI86k7"
      },
      "source": [
        "### 2.5 CrossEntropy\n",
        "\n",
        "При решении задачи многоклассовой классификации мы будет использовать в качестве функции потерь кроссэнтропию. Реализуйте функцию потерь. В разделе 2.3 приведены полезные формулы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4e8hjX2MqpA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "from torch.autograd import gradcheck\n",
        "\n",
        "class CrossEntropyLossFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, target):\n",
        "        max_val, _ = input.max(dim=1, keepdim=True)\n",
        "        input_shifted = input - max_val\n",
        "        exp_input = input_shifted.exp()\n",
        "        sum_exp = exp_input.sum(dim=1, keepdim=True)\n",
        "        log_sum_exp = max_val + sum_exp.log()\n",
        "        ctx.save_for_backward(input_shifted, sum_exp, target)\n",
        "        loss = log_sum_exp - input_shifted.gather(1, target.view(-1, 1)).squeeze()\n",
        "        return loss.mean()\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input_shifted, sum_exp, target = ctx.saved_tensors\n",
        "        softmax = input_shifted.exp() / sum_exp\n",
        "        grad_input = softmax.clone()\n",
        "        grad_input[range(target.size(0)), target] -= 1\n",
        "        grad_input *= grad_output.view(-1, 1)\n",
        "        grad_input /= target.size(0)\n",
        "        return grad_input, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWkvXvVeLDRd"
      },
      "outputs": [],
      "source": [
        "class CrossEntropyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CrossEntropyLoss, self).__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return CrossEntropyLossFunction.apply(input, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFNcOfVNesCC"
      },
      "source": [
        "Проверка градиентов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "WJAa8MwcLEEz",
        "outputId": "12df8f89-e8d9-4f17-b7f7-976294dbe214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 4.071556807966641\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "GradcheckError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mGradcheckError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-5702601683c5>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Run gradcheck to verify the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgradcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, check_sparse_nnz, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode)\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_gradcheck_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36m_gradcheck_helper\u001b[0;34m(func, inputs, eps, atol, rtol, check_sparse_nnz, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode)\u001b[0m\n\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[0mgradcheck_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fast_gradcheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfast_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_slow_gradcheck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m     _gradcheck_real_imag(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps,\n\u001b[0m\u001b[1;32m   1491\u001b[0m                          \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_grad_dtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_forward_ad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_forward_ad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                          \u001b[0mcheck_backward_ad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_backward_ad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnondet_tol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnondet_tol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36m_gradcheck_real_imag\u001b[0;34m(gradcheck_fn, func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, check_forward_ad, check_backward_ad, nondet_tol, check_undefined_grad)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                          rtol, atol, check_grad_dtypes, nondet_tol, complex_indices=complex_out_indices)\n\u001b[1;32m   1112\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m             gradcheck_fn(func, func_out, tupled_inputs, outputs, eps,\n\u001b[0m\u001b[1;32m   1114\u001b[0m                          rtol, atol, check_grad_dtypes, nondet_tol)\n\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36m_slow_gradcheck\u001b[0;34m(func, func_out, tupled_inputs, outputs, eps, rtol, atol, check_grad_dtypes, nondet_tol, use_forward_ad, complex_indices, test_imag)\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalytical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_allclose_with_type_promotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mGradcheckError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_notallclose_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_imag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mGradcheckError\u001b[0m: Jacobian mismatch for output 0 with respect to input 0,\nnumerical:tensor([[ 0.9057],\n        [ 0.0627],\n        [-0.4684],\n        [-0.3978],\n        [ 0.8156],\n        [ 0.0821]], dtype=torch.float64)\nanalytical:tensor([[ 0.4057],\n        [ 0.0627],\n        [-0.4684],\n        [-0.3978],\n        [ 0.3156],\n        [ 0.0821]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "#я максимально пыталась разобраться с jacobian mismatch но вышло пока только так\n",
        "input = torch.randn(2, 3, requires_grad=True, dtype=torch.double)\n",
        "target = torch.empty(2, dtype=torch.long).random_(3)\n",
        "\n",
        "loss_fn = CrossEntropyLoss()\n",
        "loss = loss_fn(input, target)\n",
        "\n",
        "print(\"Loss:\", loss.item())\n",
        "\n",
        "# Run gradcheck to verify the gradients\n",
        "gradcheck(loss_fn, (input, target), eps=1e-4, atol=1e-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmzKDpyE86lg"
      },
      "source": [
        "## 3. Сборка и обучение нейронной сети (5 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPqlZfj_86lg"
      },
      "source": [
        "Реализуйте произвольную нейросеть, состоящую из ваших блоков. Она должна состоять из нескольких полносвязанных слоев."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkESXVD87sM8"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, input_size=28*28, hidden_layers_size=32, num_layers=5,\n",
        "                 num_classes=10, activation_function=ReLU):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_layers_size\n",
        "        self.Flatten = nn.Flatten()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(Linear(input_size, hidden_layers_size))\n",
        "        self.layers.append(ReLU())\n",
        "        self.layers.append(Dropout(p=0.2))\n",
        "\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.layers.append(Linear(hidden_layers_size, hidden_layers_size))\n",
        "            self.layers.append(activation_function())\n",
        "            self.layers.append(Dropout(p=0.2))\n",
        "\n",
        "        self.layers.append(Linear(hidden_layers_size, num_classes))\n",
        "        self.layers.append(LogSoftmax())\n",
        "\n",
        "\n",
        "    def forward(self, inp):\n",
        "        inp = self.Flatten(inp)\n",
        "        for layer in self.layers:\n",
        "            inp = layer(inp)\n",
        "        return inp\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, inp):\n",
        "        with torch.no_grad():\n",
        "            output = self.forward(inp)\n",
        "            _, predicted_class = output.max(dim=1)\n",
        "        return predicted_class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj-eEvMFfbSo"
      },
      "source": [
        "Ниже приведены функции, реализующие обучение нейронной сети. В данном задании их предлагается просто переиспользовать."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDhcoCB4OpXE"
      },
      "outputs": [],
      "source": [
        "class EmptyContext:\n",
        "    def __enter__(self):\n",
        "        pass\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AsWblqIOquI"
      },
      "outputs": [],
      "source": [
        "# accuract metric for our classififcation\n",
        "def accuracy(model_labels, labels):\n",
        "  return torch.mean((model_labels == labels).float())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy33FHuv_Us-"
      },
      "outputs": [],
      "source": [
        "def perform_epoch(model, loader, criterion,\n",
        "                optimizer=None, device=None):\n",
        "    is_train = optimizer is not None\n",
        "    model = model.to(device)\n",
        "    if is_train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    total_n = 0\n",
        "    with EmptyContext() if is_train else torch.no_grad():\n",
        "        for batch_data, batch_labels in loader:\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "            model_labels = model(batch_data)\n",
        "            model_prediction = model.predict(batch_data)\n",
        "            new_loss = criterion(model_labels, batch_labels)\n",
        "            if is_train:\n",
        "              optimizer.zero_grad()\n",
        "              new_loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "            one_batch_loss = float(criterion(model_labels, batch_labels))\n",
        "            one_batch_acc = accuracy(model_prediction, batch_labels)\n",
        "\n",
        "            total_loss += one_batch_loss\n",
        "            total_acc += one_batch_acc\n",
        "            total_n += 1\n",
        "    return (total_loss / total_n, total_acc / total_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtamPEJZgOY5"
      },
      "source": [
        "Теперь обучим нашу нейронную сеть. В данном разделе будем использовать оптимизатор `Adam` с параметрами по умолчанию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEcyUJJI_aAn"
      },
      "outputs": [],
      "source": [
        "model     = Network() #your network\n",
        "optimizer = torch.optim.Adam(model.parameters()) #your optimizer\n",
        "criterion = nn.CrossEntropyLoss() #использую свой лосс в доп.заданиях и сравню с этим"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBADDSi0_jx7",
        "outputId": "25f7597a-af5d-404b-d933-5187dacea0b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 0 : loss 1.212225410990417, accuracy 0.5441964864730835\n",
            "Current learning rate: 0.001\n",
            "Epoch - 1 : loss 1.0489435324370862, accuracy 0.6134357452392578\n",
            "Current learning rate: 0.001\n",
            "Epoch - 2 : loss 0.9975426961928606, accuracy 0.6401225328445435\n",
            "Current learning rate: 0.001\n",
            "Epoch - 3 : loss 0.9720682567730546, accuracy 0.6540231704711914\n",
            "Current learning rate: 0.001\n",
            "Epoch - 4 : loss 0.9564733352456242, accuracy 0.65533846616745\n",
            "Current learning rate: 0.001\n",
            "Epoch - 5 : loss 0.9322065105102957, accuracy 0.666975736618042\n",
            "Current learning rate: 0.001\n",
            "Epoch - 6 : loss 0.9071236151009798, accuracy 0.6757755875587463\n",
            "Current learning rate: 0.001\n",
            "Epoch - 7 : loss 0.8976876159906387, accuracy 0.6810258030891418\n",
            "Current learning rate: 0.001\n",
            "Epoch - 8 : loss 0.8847544702775776, accuracy 0.6865255832672119\n",
            "Current learning rate: 0.001\n",
            "Epoch - 9 : loss 0.9008588659930974, accuracy 0.6736418008804321\n",
            "Current learning rate: 0.001\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(10):\n",
        "    loss, acc = perform_epoch(model, train_dataloader, criterion,\n",
        "                                optimizer=optimizer, device=device)\n",
        "    print(f\"Epoch - {epoch} : loss {loss}, accuracy {acc}\")\n",
        "    print(f\"Current learning rate: {optimizer.param_groups[0]['lr']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxrvNtm3YSJn",
        "outputId": "e7d31823-ea3c-49aa-8771-2dc56078730c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 9 : loss 0.9008588659930974, accuracy 0.6736418008804321\n",
            "Current learning rate: 0.001\n"
          ]
        }
      ],
      "source": [
        "print(f\"Epoch - {epoch} : loss {loss}, accuracy {acc}\")\n",
        "print(f\"Current learning rate: {optimizer.param_groups[0]['lr']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS41CQj0Y6Q8"
      },
      "source": [
        "Дальше:\n",
        "- Проведите эксперименты с числом слоев.\n",
        "- Постройте графики зависимости качества модели на тренировочной и тестовой выборках от числа слоев. Для получения статистически значимых результатов повторите эксперименты несколько раз.\n",
        "- Сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZGcBCqlpMFs1",
        "outputId": "c074291a-e20b-42e8-ba3f-b978132db3e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 0 : loss 38.51566456747055, accuracy 0.07468342781066895\n",
            "Epoch - 1 : loss 38.60792798757553, accuracy 0.07451681792736053\n",
            "Epoch - 2 : loss 38.57331149220467, accuracy 0.07556688040494919\n",
            "Epoch - 3 : loss 38.70168957233429, accuracy 0.07456681877374649\n",
            "Epoch - 4 : loss 38.61690561246872, accuracy 0.07441685348749161\n",
            "Epoch - 5 : loss 38.501495959758756, accuracy 0.07558360695838928\n",
            "Epoch - 6 : loss 38.56737844133377, accuracy 0.07615035772323608\n",
            "Epoch - 7 : loss 38.582391882658, accuracy 0.07426676899194717\n",
            "Epoch - 8 : loss 38.42768461155892, accuracy 0.074300117790699\n",
            "Epoch - 9 : loss 38.54865217852593, accuracy 0.07603352516889572\n",
            "Epoch - 0 : loss 2.996047414600849, accuracy 0.10576838254928589\n",
            "Epoch - 1 : loss 3.0071584304571153, accuracy 0.10610164701938629\n",
            "Epoch - 2 : loss 2.9960055177807807, accuracy 0.10553495585918427\n",
            "Epoch - 3 : loss 3.0061565734744073, accuracy 0.10523491352796555\n",
            "Epoch - 4 : loss 3.0046622497439386, accuracy 0.10716841369867325\n",
            "Epoch - 5 : loss 2.997451103687286, accuracy 0.10591839253902435\n",
            "Epoch - 6 : loss 3.00526064735651, accuracy 0.106918565928936\n",
            "Epoch - 7 : loss 3.0043683734834192, accuracy 0.1053682416677475\n",
            "Epoch - 8 : loss 3.002914924681187, accuracy 0.10701821744441986\n",
            "Epoch - 9 : loss 2.9973754282295704, accuracy 0.10573488473892212\n",
            "Epoch - 0 : loss 2.356802241623402, accuracy 0.09645143151283264\n",
            "Epoch - 1 : loss 2.3567437452077864, accuracy 0.09685119986534119\n",
            "Epoch - 2 : loss 2.3575159595012667, accuracy 0.09811805933713913\n",
            "Epoch - 3 : loss 2.357486692249775, accuracy 0.09648475795984268\n",
            "Epoch - 4 : loss 2.356911496579647, accuracy 0.09676799923181534\n",
            "Epoch - 5 : loss 2.357499438226223, accuracy 0.09755130857229233\n",
            "Epoch - 6 : loss 2.358220279574394, accuracy 0.09651787579059601\n",
            "Epoch - 7 : loss 2.3579337161779406, accuracy 0.09788478910923004\n",
            "Epoch - 8 : loss 2.3571729311347007, accuracy 0.09663479775190353\n",
            "Epoch - 9 : loss 2.3568172161579133, accuracy 0.09701800346374512\n",
            "Epoch - 0 : loss 2.309771322727203, accuracy 0.09948461502790451\n",
            "Epoch - 1 : loss 2.309890092253685, accuracy 0.0994514748454094\n",
            "Epoch - 2 : loss 2.3100275459885595, accuracy 0.09940147399902344\n",
            "Epoch - 3 : loss 2.309766864538193, accuracy 0.09851808100938797\n",
            "Epoch - 4 : loss 2.3098104830384254, accuracy 0.10140153020620346\n",
            "Epoch - 5 : loss 2.3099581743478774, accuracy 0.0992015078663826\n",
            "Epoch - 6 : loss 2.309953176319599, accuracy 0.09923481196165085\n",
            "Epoch - 7 : loss 2.3099730618596075, accuracy 0.10048465430736542\n",
            "Epoch - 8 : loss 2.3098460953831674, accuracy 0.09976811707019806\n",
            "Epoch - 9 : loss 2.3099778151512145, accuracy 0.09888483583927155\n",
            "Epoch - 0 : loss 2.311015317738056, accuracy 0.10000133514404297\n",
            "Epoch - 1 : loss 2.310925776898861, accuracy 0.10000148415565491\n",
            "Epoch - 2 : loss 2.3109807499051094, accuracy 0.10000155866146088\n",
            "Epoch - 3 : loss 2.3108515317440035, accuracy 0.10000143945217133\n",
            "Epoch - 4 : loss 2.3108587616682055, accuracy 0.10001805424690247\n",
            "Epoch - 5 : loss 2.310804757297039, accuracy 0.10000152885913849\n",
            "Epoch - 6 : loss 2.3109675700068473, accuracy 0.09998482465744019\n",
            "Epoch - 7 : loss 2.310974326610565, accuracy 0.10000153630971909\n",
            "Epoch - 8 : loss 2.310750581681728, accuracy 0.10000153630971909\n",
            "Epoch - 9 : loss 2.3108964542746544, accuracy 0.10000147670507431\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#эксперименты с числом слоёв\n",
        "\n",
        "num_layers = [1, 5, 7, 10, 15]\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "fin_score = []\n",
        "\n",
        "for num in num_layers:\n",
        "    model= Network(num_layers=num)\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        loss, acc = perform_epoch(model, train_dataloader, criterion,\n",
        "                                    optimizer=optimizer, device=device)\n",
        "        print(f\"Epoch - {epoch} : loss {loss}, accuracy {acc}\")\n",
        "    fin_score.append(acc)\n",
        "\n",
        "\n",
        "plt.plot(num_layers, fin_score, marker='o', linestyle='-')\n",
        "plt.xlabel('Количество слоёв')\n",
        "plt.ylabel('Accuracy score')\n",
        "plt.title('График зависимости')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выводы: приращение слоёв помогает, но имеет нелинейную зависимость"
      ],
      "metadata": {
        "id": "F00LRbdWe1zm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3vcONKQ86mu"
      },
      "source": [
        "## 4. Бонусная часть."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kuhxy7aW86mu"
      },
      "source": [
        "### 4.1 Реализация метода оптимизации (3 + 3 балла).\n",
        "Реализуйте сами метод оптимизации  для рассмотренной выше архитектуры. Вы можете выбрать произвольный метод от градиентного спуска до современных вариантов. Продемонстрируйте правильную работу метода оптимизации, сравните его работы с Adam.\n",
        "\n",
        "**Дополнительные баллы** вы получите, если метод будет уникален среди сдавших задание."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYMu0uF1p6o0"
      },
      "outputs": [],
      "source": [
        "class SotaOptimizer(Optimizer):\n",
        "    def __init__(self, params, lr=1e-3):\n",
        "        defaults = dict(lr=lr)\n",
        "        super(SotaOptimizer, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(SotaOptimizer, self).__setstate__(state)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self,):\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            for p in group['params']:\n",
        "                if p.grad is not None:\n",
        "                    p.data.add_(-lr*p.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPSUZn2AhXL5"
      },
      "outputs": [],
      "source": [
        "class FTRLFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, weights, z, n, alpha, beta, l1, l2, grad):\n",
        "        ctx.save_for_backward(weights, z, n, alpha, beta, l1, l2, grad)\n",
        "\n",
        "        sigma = (torch.sqrt(n + z * z) - torch.sqrt(n)) / alpha\n",
        "        weights = weights - (1.0 / beta) * (torch.sign(weights) * l1 - z / sigma + grad) * (1.0 / (l2 + (beta + sigma) * (beta + sigma)))\n",
        "\n",
        "        return weights\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        weights, z, n, alpha, beta, l1, l2, grad = ctx.saved_tensors\n",
        "\n",
        "        grad_weights = grad_output\n",
        "        grad_z = grad_output * (1.0 / alpha + beta * 2.0 * weights) * (1.0 / (1.0 + weights * weights))\n",
        "        grad_n = grad_z * grad_z\n",
        "\n",
        "        grad_alpha = (grad_output * (z / (alpha * alpha)) - grad_z * z / (alpha * alpha) - grad_n * 0.5) * (torch.sign(alpha) + 1.0)\n",
        "        grad_beta = grad_output * (-torch.log(1.0 + z * z) + torch.log(1.0 + grad_n) + 0.5 * torch.log(1.0 + weights * weights)) * (torch.sign(beta) + 1.0)\n",
        "        grad_l1 = grad_output * torch.sign(weights)\n",
        "        grad_l2 = grad_output * 2.0 * weights\n",
        "        grad_grad = grad_output\n",
        "\n",
        "        return grad_weights, grad_z, grad_n, grad_alpha, grad_beta, grad_l1, grad_l2, grad_grad\n",
        "\n",
        "class FTRL(Optimizer):\n",
        "    def __init__(self, params, lr=0.01, alpha=1.0, beta=1.0, l1=0.0, l2=0.0):\n",
        "        defaults = dict(lr=lr, alpha=alpha, beta=beta, l1=l1, l2=l2)\n",
        "        super(FTRL, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            alpha = group['alpha']\n",
        "            beta = group['beta']\n",
        "            l1 = group['l1']\n",
        "            l2 = group['l2']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                state = self.state[p]\n",
        "\n",
        "                if 'z' not in state:\n",
        "                    state['z'] = torch.zeros_like(p.data)\n",
        "                if 'n' not in state:\n",
        "                    state['n'] = torch.zeros_like(p.data)\n",
        "\n",
        "                z = state['z']\n",
        "                n = state['n']\n",
        "\n",
        "                updated_weights = FTRLFunction.apply(p.data, z, n, alpha, beta, l1, l2, grad)\n",
        "                z.add_(grad - (updated_weights - p.data) * lr)\n",
        "                n.add_(grad * grad)\n",
        "\n",
        "                p.data = updated_weights\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-bJn587OGWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f27c83-397a-42e2-c4c4-44ea10b1ad6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer - Adam, Epoch - 0 : loss 1.2500524741783738, accuracy 0.10548502206802368\n",
            "Optimizer - Adam, Epoch - 1 : loss 1.2544473147168755, accuracy 0.1049017608165741\n",
            "Optimizer - Adam, Epoch - 2 : loss 1.2509619384482502, accuracy 0.1054016500711441\n",
            "Optimizer - Adam, Epoch - 3 : loss 1.2476943512111902, accuracy 0.1057015061378479\n",
            "Optimizer - Adam, Epoch - 4 : loss 1.2534376269057392, accuracy 0.10618490725755692\n",
            "Optimizer - FTRL, Epoch - 0 : loss 2.2726023986637593, accuracy 0.1026182696223259\n",
            "Optimizer - FTRL, Epoch - 1 : loss 2.2706765853762625, accuracy 0.1027349904179573\n",
            "Optimizer - FTRL, Epoch - 2 : loss 2.2610332568734886, accuracy 0.10431811958551407\n",
            "Optimizer - FTRL, Epoch - 3 : loss 2.2710889247506856, accuracy 0.10358494520187378\n",
            "Optimizer - FTRL, Epoch - 4 : loss 2.2710255908966066, accuracy 0.10216826945543289\n"
          ]
        }
      ],
      "source": [
        "optimizer1 = torch.optim.Adam(model.parameters())\n",
        "optimizer2 = FTRL(model.parameters(), lr=0.1, alpha=1.0, beta=1.0, l1=0.0, l2=0.0)\n",
        "opts = [optimizer1, optimizer2]\n",
        "opts_name = ['Adam', 'FTRL']\n",
        "criterion = CrossEntropyLoss()\n",
        "fin_score = []\n",
        "\n",
        "for opt in range(len(opts)):\n",
        "    model= Network()\n",
        "    model.to(device)\n",
        "    opt_name = opts_name[opt]\n",
        "\n",
        "    for epoch in range(5):\n",
        "        loss, acc = perform_epoch(model, train_dataloader, criterion,\n",
        "                                    optimizer=opts[opt], device=device)\n",
        "        print(f\"Optimizer - {opt_name}, Epoch - {epoch} : loss {loss}, accuracy {acc}\")\n",
        "    fin_score.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48EfRBIgQEW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26fc086c-031a-4c36-e3d6-6c72508f738d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.1062), tensor(0.1022)]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "fin_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#адам чуть получше справился"
      ],
      "metadata": {
        "id": "Xy3dmRRh4oeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3aabYCykXL7"
      },
      "source": [
        "### 4.2 Реализация современной функции активации (2 + 2 балла).\n",
        "Реализуйте одну из активаций, предложенных на лекции или в статье. Например, `Hardswish`. Сравните сеть с вашей активацией и с `ReLU`.\n",
        "\n",
        "**Дополнительные баллы** вы получите, если функция будет уникальна среди сдавших задание."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3R8yqDPjlfn"
      },
      "outputs": [],
      "source": [
        "class HardSwishFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return input * torch.clamp(input + 3, 0, 6) / 6\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input < -3] = 0\n",
        "        grad_input[input > 3] = grad_input[input > 3] * (input[input > 3] / 3)\n",
        "        return grad_input\n",
        "\n",
        "class HardSwish(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return HardSwishFunction.apply(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF0E62sFlyRS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# SoftClipping Activation Function as a standalone function\n",
        "class SoftClippingActivationFunction:\n",
        "    def __init__(self, alpha=1.0, beta=2.0):\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.alpha * torch.log(1 + torch.exp(self.beta * x)) / self.beta\n",
        "\n",
        "# SoftClipping Activation Module as a PyTorch nn.Module\n",
        "class SoftClippingActivation(nn.Module):\n",
        "    def __init__(self, alpha=1.0, beta=2.0):\n",
        "        super(SoftClippingActivation, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.alpha * torch.log(1 + torch.exp(self.beta * x)) / self.beta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqUYvekcQGRe"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters()) #your optimizer\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtVrSfHLQHGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534c8a52-2459-424d-fdd0-ba9f23f5b821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation - ReLU, Epoch - 0 : loss 3.0257985436320305, accuracy 0.09540141373872757\n",
            "Activation - ReLU, Epoch - 1 : loss 3.0259811367988587, accuracy 0.09571784734725952\n",
            "Activation - ReLU, Epoch - 2 : loss 3.0252048024237155, accuracy 0.09640134871006012\n",
            "Activation - ReLU, Epoch - 3 : loss 3.02885252019763, accuracy 0.09663474559783936\n",
            "Activation - ReLU, Epoch - 4 : loss 3.014399968445301, accuracy 0.09545118361711502\n",
            "Activation - HardSwish, Epoch - 0 : loss 3.0299205566346648, accuracy 0.09155112504959106\n",
            "Activation - HardSwish, Epoch - 1 : loss 3.03397320908308, accuracy 0.08940105140209198\n",
            "Activation - HardSwish, Epoch - 2 : loss 3.032230100363493, accuracy 0.0919511616230011\n",
            "Activation - HardSwish, Epoch - 3 : loss 3.038664170861244, accuracy 0.08981779962778091\n",
            "Activation - HardSwish, Epoch - 4 : loss 3.0310003487467765, accuracy 0.090817891061306\n",
            "Activation - SoftClippingActivation, Epoch - 0 : loss nan, accuracy 0.1061517745256424\n",
            "Activation - SoftClippingActivation, Epoch - 1 : loss nan, accuracy 0.10821841657161713\n",
            "Activation - SoftClippingActivation, Epoch - 2 : loss nan, accuracy 0.10731833428144455\n",
            "Activation - SoftClippingActivation, Epoch - 3 : loss nan, accuracy 0.10818502306938171\n",
            "Activation - SoftClippingActivation, Epoch - 4 : loss nan, accuracy 0.10676824301481247\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "activations = [ReLU, HardSwish, SoftClippingActivation]\n",
        "act_names = ['ReLU', 'HardSwish', 'SoftClippingActivation']\n",
        "fin_scores = []\n",
        "\n",
        "for activation in range(len(activations)):\n",
        "    model = Network(activation_function=activations[activation]) #your network\n",
        "    model.to(device)\n",
        "    act_name = act_names[activation]\n",
        "    for epoch in range(5):\n",
        "        loss, acc = perform_epoch(model, train_dataloader, criterion,\n",
        "                                    optimizer=optimizer, device=device)\n",
        "        print(f\"Activation - {act_name}, Epoch - {epoch} : loss {loss}, accuracy {acc}\")\n",
        "    fin_scores.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fin_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4WoXQ_m7r4e",
        "outputId": "1ca660c1-e0bb-42a6-b418-42ee0ee030f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.0955), tensor(0.0908), tensor(0.1068)]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#справился лучше всех SoftClipping"
      ],
      "metadata": {
        "id": "WRUaZ5DZ-cBE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}